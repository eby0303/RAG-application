# localgpt/config.yaml
model_name: models/Llama-3.2-3B-Instruct-Q8_0.gguf
embed_model: intfloat/e5-small-v2
embedding_type: huggingface
device_type: cpu

# mistral-7b-instruct-v0.1.Q4_K_M  Llama-3.2-3B-Instruct-Q8_0  gemma-2-2b-it-Q8_0  phi-2.Q4_K_M
# tinyllama-1.1b-chat-v1.0.Q4_K_M openhermes-2.5-mistral-7b.Q4_K_M